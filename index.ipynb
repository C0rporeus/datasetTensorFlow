{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMFwl9IO4+86Y6zTS6mjTV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C0rporeus/datasetTensorFlow/blob/main/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwjc_G3YzWrV"
      },
      "source": [
        "#@title Texto de título predeterminado\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srqHiWEa1Az0",
        "outputId": "d4924ec2-f73a-4737-a6c2-9fc79315969c"
      },
      "source": [
        "(ds_train,ds_test), ds_info = tfds.load(\n",
        "    'div2k',#Nombre del set de datos\n",
        "     split=['train','validation'], #las opciones pueden variar, algunos tienen solo trainset, otros train, val y test set\n",
        "      with_info=True, #Guardamos en una variable la información del dataset\n",
        "      as_supervised=True, #generamos el dataset en tuplas, (imagen,etiqueta)\n",
        "      shuffle_files=True) #Revolvemos el dataset\n",
        "ds_info"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='div2k',\n",
              "    version=2.0.0,\n",
              "    description='DIV2K dataset: DIVerse 2K resolution high quality images as used for the challenges @ NTIRE (CVPR 2017 and CVPR 2018) and @ PIRM (ECCV 2018)',\n",
              "    homepage='https://data.vision.ee.ethz.ch/cvl/DIV2K/',\n",
              "    features=FeaturesDict({\n",
              "        'hr': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
              "        'lr': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
              "    }),\n",
              "    total_num_examples=900,\n",
              "    splits={\n",
              "        'train': 800,\n",
              "        'validation': 100,\n",
              "    },\n",
              "    supervised_keys=('lr', 'hr'),\n",
              "    citation=\"\"\"@InProceedings{Agustsson_2017_CVPR_Workshops,\n",
              "    \tauthor = {Agustsson, Eirikur and Timofte, Radu},\n",
              "    \ttitle = {NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study},\n",
              "    \tbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},\n",
              "        url = \"http://www.vision.ee.ethz.ch/~timofter/publications/Agustsson-CVPRW-2017.pdf\",\n",
              "    \tmonth = {July},\n",
              "    \tyear = {2017}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTJZABLa2TTw"
      },
      "source": [
        "def normalizar_datos(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "BATCH_SIZE=64\n",
        "#PARA EL SET DE ENTRENAMIENTO\n",
        "ds_train = ds_train.map(normalizar_datos)# Normalizar los datos, pasa de 0-255 a 0-1\n",
        "ds_train = ds_train.cache()#Cacheamos el set de datos para que las iteraciones tomen menos tiempo\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)#Se mezclan aleatoriamente, el buffer_size debe ser de la cantidad de datos del dataset para que sea efectivo\n",
        "ds_train = ds_train.batch(BATCH_SIZE)# agrupamos en lotes de 64 el dataset #IMPORTANTE\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE) #PRECARGAMOS EL DATASET PARA SU USO #MÁS IMPORTANTE, sin esto, no se podrá usar el dataset\n",
        "#PARA EL SET DE PRUEBA\n",
        "ds_test= ds_test.map(normalizar_datos)# Normalizar los datos, pasa de 0-255 a 0-1\n",
        "ds_test_min=ds_test\n",
        "ds_test = ds_test.batch(BATCH_SIZE)# agrupamos en lotes de 64 el dataset #IMPORTANTE\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE) #PRECARGAMOS EL DATASET PARA SU USO #MÁS IMPORTANTE, sin esto, no se podrá usar el dataset"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry5vQ01x5lYP",
        "outputId": "5153cdbc-6cb7-4e31-deed-dd2eceabb8b6"
      },
      "source": [
        "ds = tfds.load('mnist', split='train')\n",
        "ds = ds.take(1)  # tomamos solo un dato\n",
        "\n",
        "for example in ds:  # example es `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
        "  print(list(example.keys()))\n",
        "  image = example[\"image\"]\n",
        "  input_shape= image.shape\n",
        "  label = example[\"label\"]\n",
        "  print(input_shape, label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['image', 'label']\n",
            "(28, 28, 1) tf.Tensor(4, shape=(), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}